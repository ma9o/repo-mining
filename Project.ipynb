{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some global variables\n",
    "uri = None\n",
    "MAX_MONTHS = 10\n",
    "NTHREADS = 20\n",
    "NPROJECTS = 1\n",
    "project_names = ['accumulo', 'ant-ivy', 'archiva', 'aurora', 'calcite', 'cayenne', 'commons-bcel', 'commons-beanutils', 'commons-codec', 'commons-collections', 'commons-compress', 'commons-configuration', 'commons-dbcp', 'commons-digester', 'commons-imaging', 'commons-io', 'commons-jcs', 'commons-jexl', 'commons-lang', 'commons-math', 'commons-net', 'commons-rdf', 'commons-scxml', 'commons-validator', 'commons-vfs', 'deltaspike', 'falcon', 'flume', 'giraph', 'kafka', 'knox', 'kylin', 'lens', 'mahout', 'nifi', 'nutch', 'opennlp', 'parquet-mr', 'pdfbox', 'pig', 'storm', 'struts', 'systemml', 'tez', 'tika', 'wss4j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.rrule import rrule, MONTHLY\n",
    "from shutil import rmtree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    from mongoengine import connect\n",
    "    from pycoshark.mongomodels import Commit, IssueComment, Issue, Message, People, VCSSystem, Project, MailingList, IssueSystem\n",
    "    from pycoshark.utils import create_mongodb_uri_string\n",
    "except ImportError:\n",
    "    get_ipython().system('{sys.executable} -m pip install pycoshark')\n",
    "    from mongoengine import connect\n",
    "    from pycoshark.mongomodels import Commit, IssueComment, Issue, Message, People, VCSSystem, Project, MailingList, IssueSystem\n",
    "    from pycoshark.utils import create_mongodb_uri_string\n",
    "\n",
    "def undersample(df):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['comQ'] > 0:\n",
    "            positive += 1\n",
    "        else:\n",
    "            negative += 1\n",
    "\n",
    "    if positive != negative:\n",
    "        print('Class imbalance:',positive,negative)\n",
    "        random_indices = None\n",
    "        under_sample_indices = None\n",
    "        positive_idx = df[df.comQ >= 0].index\n",
    "        negative_idx = df[df.comQ < 1].index\n",
    "        if positive > negative:\n",
    "            random_indices = np.random.choice(positive_idx,negative, replace=False)\n",
    "            under_sample_indices = np.concatenate([negative_idx,random_indices])\n",
    "        if negative > positive:\n",
    "            random_indices = np.random.choice(negative_idx,positive, replace=False)\n",
    "            under_sample_indices = np.concatenate([positive_idx,random_indices])\n",
    "            \n",
    "        return df.loc[under_sample_indices]\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "def initialize(project_name):\n",
    "    global uri\n",
    "    # Create project folders\n",
    "    base = 'csv/'+str(project_name)\n",
    "    \n",
    "    if not os.path.exists(base):\n",
    "        os.mkdir(base)\n",
    "    \n",
    "    if not os.path.exists(base+'/raw'):\n",
    "        os.mkdir(base+'/raw')\n",
    "    \n",
    "    if not os.path.exists(base+'/raw/com'):\n",
    "        os.mkdir(base+'/raw/com')\n",
    "    \n",
    "    if not os.path.exists(base+'/raw/acom'):\n",
    "        os.mkdir(base+'/raw/acom')\n",
    "    \n",
    "    if not os.path.exists(base+'/raw/msg'):\n",
    "        os.mkdir(base+'/raw/msg')\n",
    "        \n",
    "    if not os.path.exists(base+'/train'):\n",
    "        os.mkdir(base+'/train')\n",
    "\n",
    "    if not os.path.exists(base+'/test_sets'):\n",
    "        os.mkdir(base+'/test_sets')\n",
    "\n",
    "    if uri is None:\n",
    "        # Database credentials\n",
    "        user = 'datascience2018'\n",
    "        password = 'qFztn73TwV'\n",
    "        host = '134.76.81.151'\n",
    "        port = '27017'\n",
    "        authentication_db = 'smartshark_test'\n",
    "        database = \"smartshark_test\"\n",
    "        ssl_enabled = None\n",
    "\n",
    "        # Establish connection\n",
    "        uri = create_mongodb_uri_string(\n",
    "            user, password, host, port, authentication_db, ssl_enabled)\n",
    "        connect(database, host=uri)\n",
    "\n",
    "    # Fetch project id and version control system id for the project\n",
    "    project = Project.objects(name=project_name).only('id').get()\n",
    "    vcs_system = VCSSystem.objects(project_id=project.id).only('id').get()\n",
    "\n",
    "    # Fetch all unique commiter IDs for the project\n",
    "    committers = []\n",
    "    for c in Commit.objects(vcs_system_id=vcs_system.id).only('committer_id'):\n",
    "        if c.committer_id not in committers:\n",
    "            committers.append(c.committer_id)\n",
    "\n",
    "    return committers\n",
    "\n",
    "# That's it\n",
    "def getQuarter(month):\n",
    "    quarter = (month+2) // 3\n",
    "    season = []\n",
    "    if quarter == 1:\n",
    "        season = [1,0,0,0]\n",
    "    if quarter == 2:\n",
    "        season = [0,1,0,0]\n",
    "    if quarter == 3:\n",
    "        season = [0,0,1,0]\n",
    "    if quarter == 4:\n",
    "        season = [0,0,0,1]\n",
    "    return season, quarter\n",
    "\n",
    "# Generate empty rows\n",
    "def getFiller(row, total_month_offset):\n",
    "    rows = []\n",
    "    prevQ = row['quarter']\n",
    "    prevY = row['year']\n",
    "    quarter_offset = 0\n",
    "    year_offset = 0\n",
    "    for month_offset in range(1,total_month_offset):\n",
    "        month = row['month']+month_offset\n",
    "        year = row['year']+year_offset\n",
    "        \n",
    "        if (month % 12) == 0:\n",
    "            month = 12\n",
    "            year += 1\n",
    "        else:\n",
    "            month = month % 12\n",
    "        \n",
    "        season, quarter = getQuarter(month)\n",
    "\n",
    "        if year > prevY:\n",
    "            year_offset += 1\n",
    "            prevY = year\n",
    "\n",
    "        if (quarter > prevQ) or (quarter == 1 and prevQ == 4): \n",
    "            quarter_offset += 1\n",
    "            prevQ = quarter\n",
    "\n",
    "        if quarter_offset > 3:\n",
    "            quarter_offset = 3\n",
    "\n",
    "        if month_offset > 5:\n",
    "            month_offset = 5\n",
    "\n",
    "        shiftedComM = [*np.zeros(month_offset)]+[*row.iloc[7:(12-month_offset)]]\n",
    "        shiftedAComM = [*np.zeros(month_offset)]+[*row.iloc[15:(20-month_offset)]]\n",
    "        shiftedMsgM = [*np.zeros(month_offset)]+[*row.iloc[23:(28-month_offset)]]\n",
    "\n",
    "        shiftedComQ = [*np.zeros(quarter_offset)]+[*row.iloc[12:(15-quarter_offset)]]\n",
    "        shiftedAComQ = [*np.zeros(quarter_offset)]+[*row.iloc[20:(23-quarter_offset)]]\n",
    "        shiftedMsgQ = [*np.zeros(quarter_offset)]+[*row.iloc[28:(31-quarter_offset)]]\n",
    "\n",
    "        r = [year, quarter, month,*season,*shiftedComM,*shiftedComQ,*shiftedAComM,*shiftedAComQ,*shiftedMsgM,*shiftedMsgQ]\n",
    "        rows.append(r)\n",
    "\n",
    "    return rows\n",
    "\n",
    "class Counter:\n",
    "    # Initialize some project specific stuff\n",
    "    def __init__(self, project_name):\n",
    "        self.project_name = project_name\n",
    "        self.project_id = Project.objects(name=project_name).only('id').get().id\n",
    "        self.vcs_system_id = VCSSystem.objects(project_id=self.project_id).only('id').get().id\n",
    "        rawdate = VCSSystem.objects(project_id=self.project_id).only('last_updated').get().last_updated\n",
    "        modM = rawdate.month % 3\n",
    "        if modM == 0:\n",
    "            self.today = datetime.date(rawdate.year,rawdate.month-2,1)\n",
    "        if modM == 1:\n",
    "            self.today = datetime.date(rawdate.year,rawdate.month,1)\n",
    "        if modM == 2:\n",
    "            self.today = datetime.date(rawdate.year,rawdate.month-1,1)\n",
    "        print('Project date set to:',self.today)\n",
    "        \n",
    "        self.mailing_list_ids = []\n",
    "        for mid in MailingList.objects(project_id=self.project_id).only('id'):\n",
    "            self.mailing_list_ids.append(mid.id)\n",
    "\n",
    "    def fillHoles(self,df,pid):\n",
    "        project_date = self.today \n",
    "        prev_row = df.iloc[0]\n",
    "        prev_date = datetime.date(prev_row['year'],prev_row['month'],1)\n",
    "        ret = pd.DataFrame([prev_row],columns=df.columns)\n",
    "        if prev_date > project_date:\n",
    "            print('First commit from the future for',pid)\n",
    "            ret = pd.DataFrame([prev_row],columns=df.columns)\n",
    "        else:\n",
    "            if df.shape[0] == 1:\n",
    "                if prev_date == project_date:\n",
    "                    ret = pd.DataFrame([prev_row],columns=df.columns)\n",
    "                else:\n",
    "                    total_month_offset = rrule(MONTHLY, dtstart=prev_date, until=project_date).count()\n",
    "                    filler = getFiller(prev_row,total_month_offset)\n",
    "                    ret = pd.DataFrame(filler,columns=df.columns)\n",
    "            else:\n",
    "                #They're sorted already. Skip the 1st row\n",
    "                for index, row in df.iloc[1:].iterrows():\n",
    "                    prev_date = datetime.date(prev_row['year'],prev_row['month'],1)\n",
    "                    now_date = datetime.date(row['year'],row['month'],1)\n",
    "                    #Check if it's the last row but still not filled\n",
    "                    if (index+1 == len(df)) and (now_date < project_date):\n",
    "                        total_month_offset = rrule(MONTHLY, dtstart=now_date, until=project_date).count()\n",
    "                        print('Hole between',now_date,'and',project_date,'. Filling',total_month_offset,'rows to fill end')  \n",
    "\n",
    "\n",
    "                        filler = getFiller(row,total_month_offset) \n",
    "                        filler_df = pd.DataFrame(filler, columns=df.columns)\n",
    "                        ret = ret.append(filler_df, ignore_index=True)\n",
    "\n",
    "                        prev_row = pd.DataFrame([filler[-1]], columns=df.columns)\n",
    "                    #Check if there's a hole in the future\n",
    "                    if now_date > project_date:\n",
    "                        print('Discarding data from',now_date,'for id',pid)\n",
    "                    else:\n",
    "                        total_month_offset = rrule(MONTHLY, dtstart=prev_date, until=now_date).count()\n",
    "                        #Check if it's the next one\n",
    "                        if total_month_offset == 2:\n",
    "                            row_df = pd.DataFrame([row],columns=df.columns)\n",
    "                            ret = ret.append(row_df, ignore_index=True)\n",
    "                            prev_row = row\n",
    "                        #Check if there's a hole in the past\n",
    "                        elif total_month_offset > 2:\n",
    "                            print('Hole between',prev_date,'and',now_date,'. Filling',total_month_offset,'rows')                        \n",
    "\n",
    "                            filler = getFiller(row, total_month_offset)\n",
    "                            filler_df = pd.DataFrame(filler, columns=df.columns)\n",
    "                            ret = ret.append(filler_df, ignore_index=True)\n",
    "\n",
    "                            row_df = pd.DataFrame([row],columns=df.columns)\n",
    "                            ret = ret.append(row_df, ignore_index=True)\n",
    "\n",
    "                            prev_row = row\n",
    "                    \n",
    "        #Should aready be sorted tho\n",
    "        ret = ret.sort_values(by=['year','month'])\n",
    "\n",
    "        if ret.tail(1).reset_index(drop=True).at[0,'month'] == 12:\n",
    "            ret.tail(2).head(1).to_csv('csv/'+str(self.project_name)+'/test_sets/'+str(pid)+'.csv')\n",
    "            if ret.shape[0] > 1:\n",
    "                ret[:-2].to_csv('csv/'+str(self.project_name)+'/train/'+str(pid)+'.csv')\n",
    "        else:\n",
    "            ret.tail(1).to_csv('csv/'+str(self.project_name)+'/test_sets/'+str(pid)+'.csv')\n",
    "            if ret.shape[0] > 1:\n",
    "                ret[:-1].to_csv('csv/'+str(self.project_name)+'/train/'+str(pid)+'.csv')\n",
    "        \n",
    "    # Count commits\n",
    "    def commits(self, pid):\n",
    "        path = 'csv/'+self.project_name+'/raw/com/'\n",
    "        fname = path+str(pid)+'.csv'\n",
    "        if not os.path.isfile(fname):\n",
    "            columns=['year','quarter','month','S1','S2','S3','S4','comM','comM1','comM2','comM3','comM4','comQ','comQ1','comQ2']\n",
    "            dates = []\n",
    "            count = []\n",
    "            print('Downloading commits for',pid,'...')\n",
    "            for c in Commit.objects(vcs_system_id=self.vcs_system_id, committer_id=pid).only('committer_date'):\n",
    "                day = c.committer_date.date()\n",
    "                if day not in dates:\n",
    "                    dates.append(day)\n",
    "                    count.append(1)\n",
    "                else:\n",
    "                    count[-1] += 1\n",
    "\n",
    "            df = pd.DataFrame(count, index=pd.to_datetime(dates), columns=['count'])\n",
    "            df = df.sort_index()\n",
    "            df = self.formatDF(df, columns)\n",
    "            df.to_csv(fname)\n",
    "        else:\n",
    "            df = pd.read_csv(fname)\n",
    "            df = df.drop('Unnamed: 0', axis = 1)\n",
    "        return df\n",
    "    \n",
    "    # Count authored commits\n",
    "    def authored_commits(self, pid):\n",
    "        path = 'csv/'+self.project_name+'/raw/acom/'\n",
    "        fname = path+str(pid)+'.csv'\n",
    "        if not os.path.isfile(fname):\n",
    "            columns=['year','quarter','month','S1','S2','S3','S4','acomM','acomM1','acomM2','acomM3','acomM4','acomQ','acomQ1','acomQ2']\n",
    "            dates = []\n",
    "            count = []\n",
    "            print('Downloading authored commits for',pid,'...')\n",
    "            for c in Commit.objects(vcs_system_id=self.vcs_system_id, author_id=pid).only('author_date'):\n",
    "                day = c.author_date.date()\n",
    "                if day not in dates:\n",
    "                    dates.append(day)\n",
    "                    count.append(1)\n",
    "                else:\n",
    "                    count[-1] += 1\n",
    "\n",
    "            df = pd.DataFrame(count, index=pd.to_datetime(dates), columns=['count'])\n",
    "            df = df.sort_index()\n",
    "            df = self.formatDF(df, columns)\n",
    "            df.to_csv(fname)\n",
    "        else:\n",
    "            df = pd.read_csv(fname)\n",
    "            df = df.drop('Unnamed: 0', axis = 1)\n",
    "        return df\n",
    "    \n",
    "    # Count messages sent, recieved and cc'd in\n",
    "    def messages(self, pid):\n",
    "        path = 'csv/'+self.project_name+'/raw/msg/'\n",
    "        fname = path+str(pid)+'.csv'\n",
    "        if not os.path.isfile(fname):\n",
    "            columns=['year','quarter','month','S1','S2','S3','S4','msgM','msgM1','msgM2','msgM3','msgM4','msgQ','msgQ1','msgQ2']\n",
    "            dates = []\n",
    "            count = []\n",
    "            print('Downloading messages for ID',pid,'...')\n",
    "            for mid in self.mailing_list_ids:\n",
    "                for c in Message.objects(mailing_list_id=mid, from_id=pid).only('date'):\n",
    "                    day = c.date.date()\n",
    "                    if day not in dates:\n",
    "                        dates.append(day)\n",
    "                        count.append(1)\n",
    "                    else:\n",
    "                        count[-1] += 1\n",
    "\n",
    "                for c in Message.objects(mailing_list_id=mid, to_ids__in=[pid]).only('date'):\n",
    "                    day = c.date.date()\n",
    "                    if day not in dates:\n",
    "                        dates.append(day)\n",
    "                        count.append(1)\n",
    "                    else:\n",
    "                        count[-1] += 1\n",
    "\n",
    "                for c in Message.objects(mailing_list_id=mid, cc_ids__in=[pid]).only('date'):\n",
    "                    day = c.date.date()\n",
    "                    if day not in dates:\n",
    "                        dates.append(day)\n",
    "                        count.append(1)\n",
    "                    else:\n",
    "                        count[-1] += 1\n",
    "\n",
    "            df = pd.DataFrame(count, index=pd.to_datetime(dates), columns=['count'])\n",
    "            df = df.sort_index()\n",
    "            df = self.formatDF(df, columns)\n",
    "            df.to_csv(fname)\n",
    "        else:\n",
    "            df = pd.read_csv(fname)\n",
    "            df = df.drop('Unnamed: 0', axis = 1)\n",
    "        return df\n",
    "\n",
    "    # Put the right values in the right boxes\n",
    "    def formatDF(self, df, col):\n",
    "        raw = []\n",
    "        row = []\n",
    "        Mcount = 0\n",
    "        Qcount = 0\n",
    "        dfq = df.resample('Q').sum()\n",
    "        dfm = df.resample('M').sum()\n",
    "        previousQ = None\n",
    "        for m in dfm.itertuples():\n",
    "            season, quarter = getQuarter(m[0].month)\n",
    "            row = [m[0].year, quarter, m[0].month, *season]\n",
    "            loc = dfm.index.get_loc(m[0])\n",
    "                \n",
    "            if Mcount == 0:\n",
    "                t = m[1]\n",
    "                t1 = 0\n",
    "                t2 = 0\n",
    "                t3 = 0\n",
    "                t4 = 0\n",
    "            elif Mcount == 1:\n",
    "                t = m[1]\n",
    "                t1 = dfm.iloc[loc-1, 0]\n",
    "                t2 = 0\n",
    "                t3 = 0\n",
    "                t4 = 0\n",
    "            elif Mcount == 2:\n",
    "                t = m[1]\n",
    "                t1 = dfm.iloc[loc-1, 0]\n",
    "                t2 = dfm.iloc[loc-2, 0]\n",
    "                t3 = 0\n",
    "                t4 = 0\n",
    "            elif Mcount == 3:\n",
    "                t = m[1]\n",
    "                t1 = dfm.iloc[loc-1, 0]\n",
    "                t2 = dfm.iloc[loc-2, 0]\n",
    "                t3 = dfm.iloc[loc-3, 0]\n",
    "                t4 = 0\n",
    "            else:\n",
    "                t = m[1]\n",
    "                t1 = dfm.iloc[loc-1, 0]\n",
    "                t2 = dfm.iloc[loc-2, 0]\n",
    "                t3 = dfm.iloc[loc-3, 0]\n",
    "                t4 = dfm.iloc[loc-4, 0]\n",
    "            Mcount += 1\n",
    "            row += [t,t1,t2,t3,t4]\n",
    "            \n",
    "            if previousQ is None:\n",
    "                previousQ = quarter\n",
    "                \n",
    "            if previousQ == 4 and quarter == 1:\n",
    "                previousQ = 0\n",
    "                \n",
    "            if quarter > previousQ:\n",
    "                Qcount += 1\n",
    "                \n",
    "            if Qcount == 0:\n",
    "                q = dfq.iloc[0,0]\n",
    "                q1 = 0\n",
    "                q2 = 0\n",
    "            elif Qcount == 1:\n",
    "                q = dfq.iloc[1,0]\n",
    "                q1 = dfq.iloc[0,0]\n",
    "                q2 = 0\n",
    "            else:\n",
    "                q = dfq.iloc[Qcount,0]\n",
    "                q1 = dfq.iloc[Qcount-1,0]\n",
    "                q2 = dfq.iloc[Qcount-2,0]\n",
    "            \n",
    "            previousQ = quarter\n",
    "                \n",
    "            row += [q,q1,q2]\n",
    "            raw.append(row)        \n",
    "        \n",
    "        return pd.DataFrame(raw, columns=col)\n",
    "\n",
    "# Just a wrapper for Counter\n",
    "class Downloader:\n",
    "    def __init__(self, project_name):\n",
    "        self.project_id = Project.objects(name=project_name).only('id').get().id\n",
    "        self.project_name = project_name\n",
    "        self.counter = Counter(self.project_name)\n",
    "\n",
    "    def download_data(self, pid):\n",
    "        raw_dir = 'csv/'+str(self.project_name)+'/raw/'\n",
    "        train_dir = 'csv/'+str(self.project_name)+'/train/'\n",
    "        fname = str(pid)+'.csv'\n",
    "        \n",
    "        if os.path.isfile(train_dir+fname):\n",
    "            #print('Found csv for ID:',pid)\n",
    "            df = pd.read_csv(train_dir+fname)\n",
    "            df = df.drop('Unnamed: 0', axis = 1)\n",
    "        else:\n",
    "            msg = self.counter.messages(pid)\n",
    "            com = self.counter.commits(pid)\n",
    "            acom = self.counter.authored_commits(pid)\n",
    "            df = pd.merge(com, acom, how='left',on=['year','quarter','month','S1','S2','S3','S4'])\n",
    "            df = df.fillna(0)\n",
    "            df = pd.merge(df, msg, how='left',on=['year','quarter','month','S1','S2','S3','S4'])\n",
    "            df = df.fillna(0)\n",
    "            df = df.sort_values(by=['year','month'])\n",
    "            df = df.astype('int64')\n",
    "            df.to_csv(raw_dir+fname)\n",
    "            self.counter.fillHoles(df,pid)\n",
    "            print('Finished downloading data for ID:',pid)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Wrapper for the random forest\n",
    "class Model:\n",
    "    def __init__(self,features):\n",
    "        labels = np.array(features['comQ'])\n",
    "\n",
    "        features= features.drop('comM', axis = 1)\n",
    "        features= features.drop('comQ', axis = 1)\n",
    "        features= features.drop('acomM', axis = 1)\n",
    "        features= features.drop('acomQ', axis = 1)\n",
    "        features= features.drop('msgM', axis = 1)\n",
    "        features= features.drop('msgQ', axis = 1)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "        self.train(train_features,train_labels)\n",
    "        self.predict(test_features)\n",
    "        self.evaluate(test_features,test_labels)\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = self.model.predict(features)\n",
    "        self.predictions = predictions\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, features, labels):\n",
    "        errors = abs(self.predictions - labels)\n",
    "        print('Mean Absolute Error:', round(np.mean(errors), 2), 'commits.')\n",
    "        \n",
    "        mase = errors.mean()/(np.abs(np.diff(features)).sum()/(features.shape[0]-1))\n",
    "        print('MASE:', mase)\n",
    "\n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)\n",
    "        plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "        plt.yticks(range(len(indices)), [self.feature_list[i] for i in indices])\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self, features, labels):\n",
    "        self.feature_list = list(features.columns)\n",
    "        features = np.array(features)\n",
    "\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf = RandomForestRegressor(n_estimators = 3000, random_state = 42)\n",
    "        rf.fit(features, labels)\n",
    "        self.model = rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "\n",
    "pool = ThreadPool(NTHREADS) \n",
    "\n",
    "def run(pid):\n",
    "    global committers\n",
    "    fname = 'csv/'+project_name+'/test_sets/'+str(pid)+'.csv'\n",
    "    i = committers.index(pid)\n",
    "    dfi = pd.read_csv(fname)\n",
    "    dfi = dfi.drop('Unnamed: 0', axis = 1)\n",
    "    columns = dfi.columns\n",
    "    dfi= dfi.drop('comM', axis = 1)\n",
    "    dfi= dfi.drop('comQ', axis = 1)\n",
    "    dfi= dfi.drop('acomM', axis = 1)\n",
    "    dfi= dfi.drop('acomQ', axis = 1)\n",
    "    dfi= dfi.drop('msgM', axis = 1)\n",
    "    dfi= dfi.drop('msgQ', axis = 1)\n",
    "    pred = np.round(model.predict(dfi))\n",
    "    if pred[0] >= 1:\n",
    "        return [pred[0],1]\n",
    "    else:\n",
    "        return [pred[0],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_t0 = time.time()\n",
    "for project_name in project_names:\n",
    "    committers = initialize(project_name)\n",
    "    downloader = Downloader(project_name)\n",
    "\n",
    "    results = pool.map(downloader.download_data, committers)\n",
    "    df = None\n",
    "    for x in results:\n",
    "        if df is None:\n",
    "            df = x\n",
    "        else:\n",
    "            df = df.append(x)\n",
    "    print(project_name,'finished loading')\n",
    "\n",
    "down_t1 = time.time()\n",
    "print('\\n Downloading phase took:',np.round(down_t1-down_t0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df = undersample(df)\n",
    "train_t0 = time.time()\n",
    "model = Model(df)\n",
    "train_t1 = time.time()\n",
    "print('Training phase took:',np.round(train_t1-train_t0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rows = []\n",
    "for project_name,i in zip(['pig'],range(NPROJECTS)):\n",
    "    r = []\n",
    "    committers = initialize(project_name)\n",
    "    testing_df = None\n",
    "    for pid in committers:\n",
    "        dfa = pd.read_csv('csv/'+project_name+'/test_sets/'+str(pid)+'.csv')\n",
    "        if testing_df is None:\n",
    "            testing_df = dfa\n",
    "        else:\n",
    "            testing_df = testing_df.append(dfa)\n",
    "    testing_df = testing_df.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "    eval_t0 = time.time()  \n",
    "    results = pool.map(run, committers)\n",
    "    eval_t1 = time.time()\n",
    "    res_df = pd.DataFrame(results, index=committers, columns=['commits','willCommit'])\n",
    "    res_df.loc['Total',:]= res_df.sum(axis=0)\n",
    "    print('Eval phase took:',np.round(eval_t1-eval_t0),'seconds')\n",
    "    s,q = getQuarter(downloader.counter.today.month)\n",
    "    print('PROJECT_NAME:',project_name)\n",
    "    print('NEXT QUARTER:',q,'\\n')\n",
    "    print('How many different committers are expected in the next quarter:',res_df.loc['Total','willCommit'])\n",
    "    print('How many commits are expected in the next quarter:',res_df.loc['Total','commits'])\n",
    "    print('Which developers will still be commiting source code in the next quarter:\\n',res_df.loc[res_df['willCommit'] == 1].index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
